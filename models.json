{
    "models": [
        {
            "name": "llama2",
            "type": "llama",
            "parameters": "7B",
            "description": "Meta's Llama 2 model",
            "arch": "llama2",
            "quantization": "Q4_K_M",
            "memory": "5GB",
            "runnable": "llama2:latest"
        },
        {
            "name": "mistral",
            "type": "AI",
            "parameters": "7B",
            "description": "Mistral AI's model",
            "arch": "mistral",
            "quantization": "Q4_K_M",
            "memory": "4.8GB",
            "runnable": "mistral:latest"
        },
        {
            "name": "dolphin-phi",
            "type": "AI",
            "parameters": "2.7B",
            "description": "Phi-2 based model",
            "arch": "phi",
            "quantization": "Q4_K_M",
            "memory": "2.5GB",
            "runnable": "dolphin-phi:latest"
        },
        {
            "name": "neural-chat",
            "type": "AI",
            "parameters": "7B",
            "description": "Intel's neural chat model",
            "arch": "neural",
            "quantization": "Q4_K_M",
            "memory": "4.8GB",
            "runnable": "neural-chat:latest"
        },
        {
            "name": "deepseek-coder",
            "type": "AI",
            "parameters": "6.7B",
            "description": "Coding specialized model",
            "arch": "deepseek",
            "quantization": "Q4_K_M",
            "memory": "4.5GB",
            "runnable": "deepseek-coder:latest"
        },
        {
            "name": "codellama",
            "type": "llama",
            "parameters": "7B",
            "description": "Meta's Code Llama model",
            "arch": "codellama",
            "quantization": "Q4_K_M",
            "memory": "4.8GB",
            "runnable": "codellama:latest"
        },
        {
            "name": "phi",
            "type": "AI",
            "parameters": "2.7B",
            "description": "Microsoft's Phi-2 model",
            "arch": "phi",
            "quantization": "Q4_K_M",
            "memory": "2.5GB",
            "runnable": "phi:latest"
        },
        {
            "name": "qwen",
            "type": "AI",
            "parameters": "7B",
            "description": "Qwen model by Alibaba",
            "arch": "qwen",
            "quantization": "Q4_K_M",
            "memory": "5GB",
            "runnable": "qwen:latest"
        },
        {
            "name": "falcon",
            "type": "AI",
            "parameters": "7B",
            "description": "TII's Falcon model",
            "arch": "falcon",
            "quantization": "Q4_K_M",
            "memory": "4.8GB",
            "runnable": "falcon:latest"
        },
        {
            "name": "stable-beluga",
            "type": "AI",
            "parameters": "7B",
            "description": "Stable Beluga model",
            "arch": "llama",
            "quantization": "Q4_K_M",
            "memory": "4.8GB",
            "runnable": "stable-beluga:latest"
        }
    ]
}